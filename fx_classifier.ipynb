{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from pair import Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classifier labels from the closing price\n",
    "def createLabels(returns: list[float], divisor: int = 1) -> list[int]:\n",
    "    scalar = np.std(returns) / divisor\n",
    "    return [int(ret / scalar) for ret in returns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>SMA_short</th>\n",
       "      <th>STD_short</th>\n",
       "      <th>SMA_long</th>\n",
       "      <th>STD_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.08195</td>\n",
       "      <td>1.08216</td>\n",
       "      <td>1.08088</td>\n",
       "      <td>1.08124</td>\n",
       "      <td>1.081868</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>1.081823</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.08124</td>\n",
       "      <td>1.08244</td>\n",
       "      <td>1.07976</td>\n",
       "      <td>1.07986</td>\n",
       "      <td>1.081906</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>1.081790</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.07986</td>\n",
       "      <td>1.08081</td>\n",
       "      <td>1.07962</td>\n",
       "      <td>1.08054</td>\n",
       "      <td>1.081488</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>1.081633</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08052</td>\n",
       "      <td>1.08172</td>\n",
       "      <td>1.08030</td>\n",
       "      <td>1.08100</td>\n",
       "      <td>1.081154</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>1.081511</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.08100</td>\n",
       "      <td>1.08206</td>\n",
       "      <td>1.08083</td>\n",
       "      <td>1.08182</td>\n",
       "      <td>1.080918</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>1.081407</td>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1.09294</td>\n",
       "      <td>1.09388</td>\n",
       "      <td>1.09271</td>\n",
       "      <td>1.09296</td>\n",
       "      <td>1.093428</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>1.093775</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1.09296</td>\n",
       "      <td>1.09298</td>\n",
       "      <td>1.09102</td>\n",
       "      <td>1.09109</td>\n",
       "      <td>1.093278</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>1.093709</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1.09109</td>\n",
       "      <td>1.09197</td>\n",
       "      <td>1.09072</td>\n",
       "      <td>1.09197</td>\n",
       "      <td>1.092800</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>1.093484</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1.09198</td>\n",
       "      <td>1.09275</td>\n",
       "      <td>1.09171</td>\n",
       "      <td>1.09214</td>\n",
       "      <td>1.092386</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1.093380</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1.09215</td>\n",
       "      <td>1.09295</td>\n",
       "      <td>1.09197</td>\n",
       "      <td>1.09262</td>\n",
       "      <td>1.092222</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1.093245</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open     high      low  ...  STD_short  SMA_long  STD_long\n",
       "0    1.08195  1.08216  1.08088  ...   0.000424  1.081823  0.000554\n",
       "1    1.08124  1.08244  1.07976  ...   0.000351  1.081790  0.000572\n",
       "2    1.07986  1.08081  1.07962  ...   0.000886  1.081633  0.000735\n",
       "3    1.08052  1.08172  1.08030  ...   0.000865  1.081511  0.000754\n",
       "4    1.08100  1.08206  1.08083  ...   0.000698  1.081407  0.000708\n",
       "..       ...      ...      ...  ...        ...       ...       ...\n",
       "475  1.09294  1.09388  1.09271  ...   0.000425  1.093775  0.000421\n",
       "476  1.09296  1.09298  1.09102  ...   0.000432  1.093709  0.000463\n",
       "477  1.09109  1.09197  1.09072  ...   0.000952  1.093484  0.000764\n",
       "478  1.09198  1.09275  1.09171  ...   0.000752  1.093380  0.000852\n",
       "479  1.09215  1.09295  1.09197  ...   0.000697  1.093245  0.000877\n",
       "\n",
       "[480 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature creation\n",
    "eurusd = Pair('EURUSD', key='q0tsF6PmO8kro7SlVt0S', mode='hourly')\n",
    "eurusd.ts = pd.DataFrame(eurusd.ts)\n",
    "\n",
    "shorter = 5\n",
    "longer = 15\n",
    "\n",
    "sma_long = [None] * longer\n",
    "sma_short = [None] * shorter\n",
    "std_long = [None] * longer\n",
    "std_short = [None] * shorter\n",
    "\n",
    "for i in range(len(eurusd.ts) - 5):\n",
    "    sma_short.append(np.mean(eurusd.ts.close[i:i+5]))\n",
    "    std_short.append(np.std(eurusd.ts.close[i:i+5]))\n",
    "\n",
    "    if not i >= len(eurusd.ts) - 15:\n",
    "        sma_long.append(np.mean(eurusd.ts.close[i:i+15]))\n",
    "        std_long.append(np.std(eurusd.ts.close[i:i+15]))\n",
    "\n",
    "eurusd.ts['SMA_short'] = sma_short\n",
    "eurusd.ts['STD_short'] = std_short\n",
    "eurusd.ts['SMA_long'] = sma_long\n",
    "eurusd.ts['STD_long'] = std_long\n",
    "\n",
    "df = eurusd.ts[['open', 'high', 'low', 'close', 'SMA_short', 'STD_short', 'SMA_long', 'STD_long']].iloc[15:,:].reset_index(drop=True)\n",
    "features = df.iloc[:-1,:]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label creation\n",
    "labels_no_arr = createLabels(eurusd.logrs, 2)\n",
    "label_arr = tensorflow.keras.utils.to_categorical(labels_no_arr, dtype='int64')\n",
    "labels = label_arr[15:]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=.15)\n",
    "\n",
    "ct = ColumnTransformer([('only numeric', MinMaxScaler(), features.columns)], remainder='passthrough')\n",
    "features_train = ct.fit_transform(features_train)\n",
    "features_test = ct.fit_transform(features_test)\n",
    "all_features = ct.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new model FXc\n",
      "Model: \"FXc\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               4608      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 11)                99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,835\n",
      "Trainable params: 189,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model: Sequential\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "build = 1\n",
    "activ = 'relu'\n",
    "\n",
    "def build_model(name: str = 'FXc', metrics = metrics, loss = loss):\n",
    "    model = Sequential(name = name)\n",
    "    model.add(layers.InputLayer(input_shape=features.shape[1],))\n",
    "    model.add(layers.Dense(512, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(256, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(128, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(128, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(32, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(8, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(label_arr.shape[1], name='Output', activation='softmax'))\n",
    "    model.compile(loss=loss, optimizer=Adam(learning_rate=0.002), metrics=metrics)\n",
    "    print(f'Generating new model {model.name}')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "if 'model' not in dir() or build: model = build_model()\n",
    "else: print('Loaded previous model:'); model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "109/109 [==============================] - 1s 8ms/step - loss: 1.6350 - accuracy: 0.4847 - val_loss: 1.5428 - val_accuracy: 0.5976\n",
      "Epoch 2/300\n",
      "109/109 [==============================] - 1s 9ms/step - loss: 1.6165 - accuracy: 0.4847 - val_loss: 1.5516 - val_accuracy: 0.5610\n",
      "Epoch 3/300\n",
      "109/109 [==============================] - 1s 8ms/step - loss: 1.6027 - accuracy: 0.4847 - val_loss: 1.6333 - val_accuracy: 0.5976\n",
      "Epoch 4/300\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 1.6093 - accuracy: 0.4816 - val_loss: 1.5606 - val_accuracy: 0.5976\n",
      "Epoch 5/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.6241 - accuracy: 0.4816 - val_loss: 1.7116 - val_accuracy: 0.5610\n",
      "Epoch 6/300\n",
      "109/109 [==============================] - 1s 8ms/step - loss: 1.5949 - accuracy: 0.4847 - val_loss: 1.6100 - val_accuracy: 0.5976\n",
      "Epoch 7/300\n",
      "109/109 [==============================] - 1s 8ms/step - loss: 1.5860 - accuracy: 0.4877 - val_loss: 1.7314 - val_accuracy: 0.5488\n",
      "Epoch 8/300\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 1.5867 - accuracy: 0.4877 - val_loss: 1.6632 - val_accuracy: 0.5366\n",
      "Epoch 9/300\n",
      "109/109 [==============================] - 1s 8ms/step - loss: 1.5780 - accuracy: 0.5000 - val_loss: 1.7242 - val_accuracy: 0.5732\n",
      "Epoch 10/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5907 - accuracy: 0.4877 - val_loss: 1.7611 - val_accuracy: 0.5976\n",
      "Epoch 11/300\n",
      "109/109 [==============================] - 1s 9ms/step - loss: 1.5721 - accuracy: 0.4939 - val_loss: 1.7431 - val_accuracy: 0.5854\n",
      "Epoch 12/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5776 - accuracy: 0.4908 - val_loss: 1.7852 - val_accuracy: 0.5976\n",
      "Epoch 13/300\n",
      "109/109 [==============================] - 1s 9ms/step - loss: 1.5798 - accuracy: 0.4939 - val_loss: 1.7450 - val_accuracy: 0.5854\n",
      "Epoch 14/300\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 1.5856 - accuracy: 0.4939 - val_loss: 1.8057 - val_accuracy: 0.5976\n",
      "Epoch 15/300\n",
      "109/109 [==============================] - 1s 9ms/step - loss: 1.5709 - accuracy: 0.4877 - val_loss: 1.7807 - val_accuracy: 0.5976\n",
      "Epoch 16/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5499 - accuracy: 0.4908 - val_loss: 1.9777 - val_accuracy: 0.6098\n",
      "Epoch 17/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5755 - accuracy: 0.4847 - val_loss: 1.8729 - val_accuracy: 0.5610\n",
      "Epoch 18/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5576 - accuracy: 0.4969 - val_loss: 2.0622 - val_accuracy: 0.5854\n",
      "Epoch 19/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.6682 - accuracy: 0.4785 - val_loss: 1.5770 - val_accuracy: 0.5976\n",
      "Epoch 20/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5937 - accuracy: 0.4847 - val_loss: 1.6553 - val_accuracy: 0.5976\n",
      "Epoch 21/300\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 1.5818 - accuracy: 0.4877 - val_loss: 1.6400 - val_accuracy: 0.5976\n",
      "Epoch 22/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5436 - accuracy: 0.4908 - val_loss: 1.7806 - val_accuracy: 0.5976\n",
      "Epoch 23/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5904 - accuracy: 0.4877 - val_loss: 1.6253 - val_accuracy: 0.5976\n",
      "Epoch 24/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5606 - accuracy: 0.4908 - val_loss: 1.6733 - val_accuracy: 0.5976\n",
      "Epoch 25/300\n",
      "109/109 [==============================] - 1s 9ms/step - loss: 1.5623 - accuracy: 0.4969 - val_loss: 1.7159 - val_accuracy: 0.5854\n",
      "Epoch 26/300\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 1.5474 - accuracy: 0.4939 - val_loss: 1.7235 - val_accuracy: 0.5976\n",
      "Epoch 27/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5497 - accuracy: 0.4969 - val_loss: 1.8677 - val_accuracy: 0.5610\n",
      "Epoch 28/300\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 1.5669 - accuracy: 0.4908 - val_loss: 1.8455 - val_accuracy: 0.5488\n",
      "Epoch 29/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5501 - accuracy: 0.4877 - val_loss: 1.8755 - val_accuracy: 0.5976\n",
      "Epoch 30/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5420 - accuracy: 0.4939 - val_loss: 1.9045 - val_accuracy: 0.5976\n",
      "Epoch 31/300\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 1.5523 - accuracy: 0.4939 - val_loss: 2.0906 - val_accuracy: 0.5976\n",
      "Epoch 32/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5336 - accuracy: 0.4939 - val_loss: 1.9393 - val_accuracy: 0.5976\n",
      "Epoch 33/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5467 - accuracy: 0.4908 - val_loss: 1.9741 - val_accuracy: 0.5854\n",
      "Epoch 34/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5313 - accuracy: 0.4969 - val_loss: 2.1337 - val_accuracy: 0.5854\n",
      "Epoch 35/300\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 1.5445 - accuracy: 0.5031 - val_loss: 2.2452 - val_accuracy: 0.5732\n",
      "Epoch 36/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5600 - accuracy: 0.5000 - val_loss: 2.1141 - val_accuracy: 0.5732\n",
      "Epoch 37/300\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 1.5431 - accuracy: 0.4939 - val_loss: 2.1440 - val_accuracy: 0.5244\n",
      "Epoch 38/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5320 - accuracy: 0.5000 - val_loss: 2.3179 - val_accuracy: 0.5976\n",
      "Epoch 39/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5120 - accuracy: 0.4969 - val_loss: 2.1426 - val_accuracy: 0.5854\n",
      "Epoch 40/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5830 - accuracy: 0.4939 - val_loss: 1.6637 - val_accuracy: 0.5976\n",
      "Epoch 41/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5762 - accuracy: 0.4969 - val_loss: 1.8575 - val_accuracy: 0.5854\n",
      "Epoch 42/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5385 - accuracy: 0.5031 - val_loss: 2.1142 - val_accuracy: 0.5854\n",
      "Epoch 43/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5356 - accuracy: 0.4969 - val_loss: 2.2838 - val_accuracy: 0.5976\n",
      "Epoch 44/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5245 - accuracy: 0.5031 - val_loss: 2.1340 - val_accuracy: 0.5122\n",
      "Epoch 45/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5238 - accuracy: 0.5000 - val_loss: 2.3255 - val_accuracy: 0.5122\n",
      "Epoch 46/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5242 - accuracy: 0.4969 - val_loss: 2.2606 - val_accuracy: 0.5732\n",
      "Epoch 47/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5202 - accuracy: 0.5000 - val_loss: 2.3393 - val_accuracy: 0.5610\n",
      "Epoch 48/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5137 - accuracy: 0.5061 - val_loss: 2.2078 - val_accuracy: 0.5976\n",
      "Epoch 49/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.6137 - accuracy: 0.4785 - val_loss: 1.7172 - val_accuracy: 0.5976\n",
      "Epoch 50/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5482 - accuracy: 0.4877 - val_loss: 1.7915 - val_accuracy: 0.5976\n",
      "Epoch 51/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5505 - accuracy: 0.4908 - val_loss: 1.7671 - val_accuracy: 0.5976\n",
      "Epoch 52/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5168 - accuracy: 0.4939 - val_loss: 1.8729 - val_accuracy: 0.5488\n",
      "Epoch 53/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5182 - accuracy: 0.4969 - val_loss: 1.9829 - val_accuracy: 0.5366\n",
      "Epoch 54/300\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 1.5126 - accuracy: 0.5031 - val_loss: 2.1363 - val_accuracy: 0.5976\n",
      "Epoch 55/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5006 - accuracy: 0.5123 - val_loss: 2.1514 - val_accuracy: 0.5000\n",
      "Epoch 56/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5139 - accuracy: 0.4939 - val_loss: 2.1407 - val_accuracy: 0.5000\n",
      "Epoch 57/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5292 - accuracy: 0.4969 - val_loss: 2.1392 - val_accuracy: 0.5854\n",
      "Epoch 58/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.4852 - accuracy: 0.5061 - val_loss: 2.2316 - val_accuracy: 0.5122\n",
      "Epoch 59/300\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 1.5119 - accuracy: 0.4939 - val_loss: 2.5310 - val_accuracy: 0.5854\n",
      "Epoch 60/300\n",
      "109/109 [==============================] - 0s 4ms/step - loss: 1.5696 - accuracy: 0.4939 - val_loss: 2.4405 - val_accuracy: 0.5976\n",
      "Epoch 61/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5159 - accuracy: 0.5092 - val_loss: 2.7587 - val_accuracy: 0.5854\n",
      "Epoch 62/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.4992 - accuracy: 0.5031 - val_loss: 2.8530 - val_accuracy: 0.4756\n",
      "Epoch 63/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.4952 - accuracy: 0.5245 - val_loss: 2.9638 - val_accuracy: 0.5122\n",
      "Epoch 64/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5009 - accuracy: 0.5123 - val_loss: 2.6214 - val_accuracy: 0.4878\n",
      "Epoch 65/300\n",
      "109/109 [==============================] - 0s 5ms/step - loss: 1.4828 - accuracy: 0.5153 - val_loss: 2.7490 - val_accuracy: 0.5122\n",
      "Epoch 66/300\n",
      "109/109 [==============================] - 1s 5ms/step - loss: 1.5108 - accuracy: 0.5061 - val_loss: 2.5692 - val_accuracy: 0.4878\n",
      "Epoch 66: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=50, verbose=1)\n",
    "history = model.fit(features_train, labels_train, batch_size=3, epochs=300, verbose=1, validation_split=.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = model.predict(features_test)\n",
    "y_est = np.argmax(y_est, axis=1)\n",
    "y_true = np.argmax(labels_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.69        39\n",
      "           1       0.40      0.25      0.31         8\n",
      "           2       0.25      0.33      0.29         3\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.51        72\n",
      "   macro avg       0.12      0.15      0.13        72\n",
      "weighted avg       0.36      0.51      0.42        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  1  1  3  0  0  0  0  0  0]\n",
      " [ 6  2  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  1  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  1  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian adjustment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
