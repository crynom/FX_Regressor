{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from pair import Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating classifier labels from the closing price\n",
    "def createLabels(returns: list[float], divisor: int = 1) -> list[int]:\n",
    "    scalar = np.std(returns) / divisor\n",
    "    labels = [int(ret / scalar) for ret in returns]\n",
    "    return [l - min(labels) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>SMA_short</th>\n",
       "      <th>STD_short</th>\n",
       "      <th>SMA_long</th>\n",
       "      <th>STD_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.09516</td>\n",
       "      <td>1.09524</td>\n",
       "      <td>1.09430</td>\n",
       "      <td>1.09447</td>\n",
       "      <td>1.094062</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.092379</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.09446</td>\n",
       "      <td>1.09723</td>\n",
       "      <td>1.09445</td>\n",
       "      <td>1.09655</td>\n",
       "      <td>1.094332</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>1.092641</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.09655</td>\n",
       "      <td>1.09768</td>\n",
       "      <td>1.09618</td>\n",
       "      <td>1.09660</td>\n",
       "      <td>1.094850</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>1.093031</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.09660</td>\n",
       "      <td>1.09688</td>\n",
       "      <td>1.09425</td>\n",
       "      <td>1.09490</td>\n",
       "      <td>1.095376</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>1.093396</td>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.09491</td>\n",
       "      <td>1.09630</td>\n",
       "      <td>1.09460</td>\n",
       "      <td>1.09600</td>\n",
       "      <td>1.095534</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>1.093655</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1.10386</td>\n",
       "      <td>1.10450</td>\n",
       "      <td>1.10210</td>\n",
       "      <td>1.10446</td>\n",
       "      <td>1.104492</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1.106343</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1.10446</td>\n",
       "      <td>1.10536</td>\n",
       "      <td>1.10425</td>\n",
       "      <td>1.10493</td>\n",
       "      <td>1.104534</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>1.106221</td>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1.10492</td>\n",
       "      <td>1.10548</td>\n",
       "      <td>1.10412</td>\n",
       "      <td>1.10425</td>\n",
       "      <td>1.104616</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>1.106099</td>\n",
       "      <td>0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1.10424</td>\n",
       "      <td>1.10424</td>\n",
       "      <td>1.10356</td>\n",
       "      <td>1.10395</td>\n",
       "      <td>1.104476</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.105891</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1.10396</td>\n",
       "      <td>1.10458</td>\n",
       "      <td>1.10358</td>\n",
       "      <td>1.10453</td>\n",
       "      <td>1.104290</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>1.105615</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open     high      low    close  SMA_short  STD_short  SMA_long  \\\n",
       "0    1.09516  1.09524  1.09430  1.09447   1.094062   0.000647  1.092379   \n",
       "1    1.09446  1.09723  1.09445  1.09655   1.094332   0.000449  1.092641   \n",
       "2    1.09655  1.09768  1.09618  1.09660   1.094850   0.000943  1.093031   \n",
       "3    1.09660  1.09688  1.09425  1.09490   1.095376   0.001035  1.093396   \n",
       "4    1.09491  1.09630  1.09460  1.09600   1.095534   0.000878  1.093655   \n",
       "..       ...      ...      ...      ...        ...        ...       ...   \n",
       "483  1.10386  1.10450  1.10210  1.10446   1.104492   0.000405  1.106343   \n",
       "484  1.10446  1.10536  1.10425  1.10493   1.104534   0.000388  1.106221   \n",
       "485  1.10492  1.10548  1.10412  1.10425   1.104616   0.000419  1.106099   \n",
       "486  1.10424  1.10424  1.10356  1.10395   1.104476   0.000400  1.105891   \n",
       "487  1.10396  1.10458  1.10358  1.10453   1.104290   0.000385  1.105615   \n",
       "\n",
       "     STD_long  \n",
       "0    0.001416  \n",
       "1    0.001415  \n",
       "2    0.001618  \n",
       "3    0.001758  \n",
       "4    0.001671  \n",
       "..        ...  \n",
       "483  0.001416  \n",
       "484  0.001492  \n",
       "485  0.001518  \n",
       "486  0.001543  \n",
       "487  0.001495  \n",
       "\n",
       "[488 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature creation\n",
    "eurusd = Pair('EURUSD', key='q0tsF6PmO8kro7SlVt0S', mode='hourly')\n",
    "eurusd.ts = pd.DataFrame(eurusd.ts)\n",
    "\n",
    "shorter = 5\n",
    "longer = 15\n",
    "\n",
    "sma_long = [None] * longer\n",
    "sma_short = [None] * shorter\n",
    "std_long = [None] * longer\n",
    "std_short = [None] * shorter\n",
    "\n",
    "for i in range(len(eurusd.ts) - 5):\n",
    "    sma_short.append(np.mean(eurusd.ts.close[i:i+5]))\n",
    "    std_short.append(np.std(eurusd.ts.close[i:i+5]))\n",
    "\n",
    "    if not i >= len(eurusd.ts) - 15:\n",
    "        sma_long.append(np.mean(eurusd.ts.close[i:i+15]))\n",
    "        std_long.append(np.std(eurusd.ts.close[i:i+15]))\n",
    "\n",
    "eurusd.ts['SMA_short'] = sma_short\n",
    "eurusd.ts['STD_short'] = std_short\n",
    "eurusd.ts['SMA_long'] = sma_long\n",
    "eurusd.ts['STD_long'] = std_long\n",
    "\n",
    "df = eurusd.ts[['open', 'high', 'low', 'close', 'SMA_short', 'STD_short', 'SMA_long', 'STD_long']].iloc[15:,:].reset_index(drop=True)\n",
    "features = df.iloc[:-1,:]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label creation\n",
    "labels_no_arr = createLabels(eurusd.logrs, 2)\n",
    "label_arr = tensorflow.keras.utils.to_categorical(labels_no_arr, dtype='int64')\n",
    "labels = label_arr[15:]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=.15)\n",
    "\n",
    "ct = ColumnTransformer([('only numeric', MinMaxScaler(), features.columns)], remainder='passthrough')\n",
    "features_train = ct.fit_transform(features_train)\n",
    "features_test = ct.fit_transform(features_test)\n",
    "all_features = ct.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new model FXc\n",
      "Model: \"FXc\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               4608      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 22)                198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,934\n",
      "Trainable params: 189,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model: Sequential\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "build = 1\n",
    "activ = 'relu'\n",
    "\n",
    "def build_model(name: str = 'FXc', metrics = metrics, loss = loss):\n",
    "    model = Sequential(name = name)\n",
    "    model.add(layers.InputLayer(input_shape=features.shape[1],))\n",
    "    model.add(layers.Dense(512, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(256, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(128, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(128, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(32, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(8, activation=activ))\n",
    "    # model.add(layers.Dropout(.1))\n",
    "    model.add(layers.Dense(label_arr.shape[1], name='Output', activation='softmax'))\n",
    "    model.compile(loss=loss, optimizer=Adam(learning_rate=0.0075), metrics=metrics)\n",
    "    print(f'Generating new model {model.name}')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "if 'model' not in dir() or build: model = build_model()\n",
    "else: print('Loaded previous model:'); model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "117/117 [==============================] - 3s 10ms/step - loss: 2.2517 - accuracy: 0.4587 - val_loss: 1.6946 - val_accuracy: 0.5397\n",
      "Epoch 2/300\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.6195 - accuracy: 0.5442 - val_loss: 1.7185 - val_accuracy: 0.5397\n",
      "Epoch 3/300\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 1.6068 - accuracy: 0.5442 - val_loss: 1.7052 - val_accuracy: 0.5397\n",
      "Epoch 4/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5846 - accuracy: 0.5442 - val_loss: 1.7643 - val_accuracy: 0.5397\n",
      "Epoch 5/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.6276 - accuracy: 0.5442 - val_loss: 1.6972 - val_accuracy: 0.5397\n",
      "Epoch 6/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.6038 - accuracy: 0.5442 - val_loss: 1.8804 - val_accuracy: 0.5397\n",
      "Epoch 7/300\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 1.5881 - accuracy: 0.5442 - val_loss: 1.8244 - val_accuracy: 0.5397\n",
      "Epoch 8/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5865 - accuracy: 0.5442 - val_loss: 1.8888 - val_accuracy: 0.5397\n",
      "Epoch 9/300\n",
      "117/117 [==============================] - 1s 9ms/step - loss: 1.5866 - accuracy: 0.5442 - val_loss: 1.7358 - val_accuracy: 0.5397\n",
      "Epoch 10/300\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.5736 - accuracy: 0.5442 - val_loss: 1.7201 - val_accuracy: 0.5397\n",
      "Epoch 11/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5755 - accuracy: 0.5442 - val_loss: 1.7135 - val_accuracy: 0.5397\n",
      "Epoch 12/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5773 - accuracy: 0.5442 - val_loss: 1.7090 - val_accuracy: 0.5397\n",
      "Epoch 13/300\n",
      "117/117 [==============================] - 1s 8ms/step - loss: 1.5754 - accuracy: 0.5442 - val_loss: 1.7470 - val_accuracy: 0.5397\n",
      "Epoch 14/300\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 1.5565 - accuracy: 0.5442 - val_loss: 1.6949 - val_accuracy: 0.5397\n",
      "Epoch 15/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5673 - accuracy: 0.5442 - val_loss: 1.7907 - val_accuracy: 0.5397\n",
      "Epoch 16/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5571 - accuracy: 0.5442 - val_loss: 1.7225 - val_accuracy: 0.5397\n",
      "Epoch 17/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5581 - accuracy: 0.5413 - val_loss: 1.6977 - val_accuracy: 0.5397\n",
      "Epoch 18/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5644 - accuracy: 0.5442 - val_loss: 1.9634 - val_accuracy: 0.5397\n",
      "Epoch 19/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5598 - accuracy: 0.5442 - val_loss: 1.7226 - val_accuracy: 0.5397\n",
      "Epoch 20/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5501 - accuracy: 0.5442 - val_loss: 1.7483 - val_accuracy: 0.5397\n",
      "Epoch 21/300\n",
      "117/117 [==============================] - 1s 8ms/step - loss: 1.5529 - accuracy: 0.5442 - val_loss: 1.8537 - val_accuracy: 0.5397\n",
      "Epoch 22/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5684 - accuracy: 0.5413 - val_loss: 1.7482 - val_accuracy: 0.5397\n",
      "Epoch 23/300\n",
      "117/117 [==============================] - 1s 8ms/step - loss: 1.6275 - accuracy: 0.5385 - val_loss: 1.8956 - val_accuracy: 0.5397\n",
      "Epoch 24/300\n",
      "117/117 [==============================] - 1s 8ms/step - loss: 1.6030 - accuracy: 0.5442 - val_loss: 1.7443 - val_accuracy: 0.5397\n",
      "Epoch 25/300\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.5739 - accuracy: 0.5442 - val_loss: 1.7741 - val_accuracy: 0.5397\n",
      "Epoch 26/300\n",
      "117/117 [==============================] - 1s 9ms/step - loss: 1.6015 - accuracy: 0.5442 - val_loss: 1.7260 - val_accuracy: 0.5397\n",
      "Epoch 27/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5619 - accuracy: 0.5413 - val_loss: 1.7250 - val_accuracy: 0.5397\n",
      "Epoch 28/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5554 - accuracy: 0.5442 - val_loss: 1.7231 - val_accuracy: 0.5397\n",
      "Epoch 29/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5666 - accuracy: 0.5442 - val_loss: 1.7102 - val_accuracy: 0.5397\n",
      "Epoch 30/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5449 - accuracy: 0.5442 - val_loss: 1.8064 - val_accuracy: 0.5397\n",
      "Epoch 31/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5528 - accuracy: 0.5442 - val_loss: 1.7219 - val_accuracy: 0.5397\n",
      "Epoch 32/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5427 - accuracy: 0.5442 - val_loss: 1.9526 - val_accuracy: 0.5397\n",
      "Epoch 33/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5534 - accuracy: 0.5442 - val_loss: 1.7708 - val_accuracy: 0.5397\n",
      "Epoch 34/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5490 - accuracy: 0.5442 - val_loss: 1.6942 - val_accuracy: 0.5397\n",
      "Epoch 35/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5425 - accuracy: 0.5442 - val_loss: 1.8207 - val_accuracy: 0.5397\n",
      "Epoch 36/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5541 - accuracy: 0.5442 - val_loss: 1.9107 - val_accuracy: 0.5397\n",
      "Epoch 37/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5444 - accuracy: 0.5442 - val_loss: 1.9151 - val_accuracy: 0.5397\n",
      "Epoch 38/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5640 - accuracy: 0.5442 - val_loss: 1.8519 - val_accuracy: 0.5397\n",
      "Epoch 39/300\n",
      "117/117 [==============================] - 1s 7ms/step - loss: 1.5527 - accuracy: 0.5442 - val_loss: 1.7025 - val_accuracy: 0.5397\n",
      "Epoch 40/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5644 - accuracy: 0.5413 - val_loss: 1.7255 - val_accuracy: 0.5397\n",
      "Epoch 41/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5604 - accuracy: 0.5442 - val_loss: 1.7223 - val_accuracy: 0.5397\n",
      "Epoch 42/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5547 - accuracy: 0.5442 - val_loss: 1.8879 - val_accuracy: 0.5397\n",
      "Epoch 43/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5411 - accuracy: 0.5442 - val_loss: 1.9589 - val_accuracy: 0.5397\n",
      "Epoch 44/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5573 - accuracy: 0.5442 - val_loss: 1.6814 - val_accuracy: 0.5397\n",
      "Epoch 45/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5489 - accuracy: 0.5442 - val_loss: 1.8148 - val_accuracy: 0.5397\n",
      "Epoch 46/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5331 - accuracy: 0.5442 - val_loss: 1.8817 - val_accuracy: 0.5397\n",
      "Epoch 47/300\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 1.5477 - accuracy: 0.5442 - val_loss: 1.8272 - val_accuracy: 0.5397\n",
      "Epoch 48/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5356 - accuracy: 0.5442 - val_loss: 1.8895 - val_accuracy: 0.5397\n",
      "Epoch 49/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5308 - accuracy: 0.5442 - val_loss: 1.8938 - val_accuracy: 0.5397\n",
      "Epoch 50/300\n",
      "117/117 [==============================] - 1s 5ms/step - loss: 1.5362 - accuracy: 0.5442 - val_loss: 2.1319 - val_accuracy: 0.5397\n",
      "Epoch 51/300\n",
      "117/117 [==============================] - 1s 6ms/step - loss: 1.5332 - accuracy: 0.5442 - val_loss: 1.8694 - val_accuracy: 0.5397\n",
      "Epoch 51: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=50, verbose=1)\n",
    "history = model.fit(features_train, labels_train, batch_size=3, epochs=300, verbose=1, validation_split=.15, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = model.predict(features_test)\n",
    "y_est = np.argmax(y_est, axis=1)\n",
    "y_true = np.argmax(labels_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.49      1.00      0.65        36\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00         4\n",
      "          15       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49        74\n",
      "   macro avg       0.06      0.12      0.08        74\n",
      "weighted avg       0.24      0.49      0.32        74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  6  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0  0]\n",
      " [ 0  0  0 11  0  0  0  0]\n",
      " [ 0  0  0  4  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#actual is horizontal\n",
    "#predicted is vertical\n",
    "\n",
    "print(confusion_matrix(y_true, y_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian adjustment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
